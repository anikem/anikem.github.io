<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-110663561-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-110663561-1');
  </script>

  <!-- Default Statcounter code for My Personal Website https://anikem.github.io/ -->
  <script type="text/javascript">
  var sc_project=12203587;
  var sc_invisible=1;
  var sc_security="67fbccb9";
  var sc_https=1;
  var sc_remove_link=1;
  </script>
  <script type="text/javascript"
  src="https://www.statcounter.com/counter/counter.js" async></script>
  <noscript><div class="statcounter"><img class="statcounter"
  src="https://c.statcounter.com/12203587/0/67fbccb9/1/" alt="Web
  Analytics"></div></noscript>
  <!-- End of Statcounter Code -->

  <title>Aniruddha (Ani) Kembhavi</title>
  <meta name="author" content="Ani Kembhavi">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- CSS  -->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <link href="css/materialize.css" type="text/css" rel="stylesheet" media="screen,projection"/>
  <link href="css/style.css" type="text/css" rel="stylesheet" media="screen,projection"/>
</head>

<body>

<!--
  Navigation Bar
-->

<div class="navbar-fixed">
  <nav class="white lighten-5" role="navigation">
    <div class="nav-wrapper container">
      <a id="logo-container" href="#" class="brand-logo black-text">Ani Kembhavi</a>
      <ul class="right hide-on-med-and-down">
        <li><a href="#" class="black-text">Home</a></li>
        <li><a href="#research" class="black-text">Research</a></li>
        <li><a href="#recent" class="black-text">Recent Highlights</a></li>
        <li><a href="#publications" class="black-text">Publications</a></li>
        <li><a href="#collaborators" class="black-text">Collaborators</a></li>
        <li><a href="#press" class="black-text">Press</a></li>
      </ul>

      <ul id="nav-mobile" class="sidenav">
        <li><a href="#" class="black-text">Home</a></li>
        <li><a href="#research" class="black-text">Research</a></li>
        <li><a href="#recent" class="black-text">Recent Highlights</a></li>
        <li><a href="#publications" class="black-text">Publications</a></li>
        <li><a href="#collaborators" class="black-text">Collaborators</a></li>
        <li><a href="#press" class="black-text">Press</a></li>
      </ul>
      <a href="#" data-target="nav-mobile" class="sidenav-trigger light-blue-text"><i class="material-icons">menu</i></a>
    </div>
  </nav>
</div>

<!--
  Introduction
-->

<div class="container">
  <div class="section">
    <div class="row">
      <p></p>
    </div>
  <div class="row">
    <div class="col s12 m9">
        <h6 class="light">
          <p>
            I lead <a href="https://prior.allenai.org/" target="_blank">PRIOR</a>, the computer vision team at the <a href="http://allenai.org/" target="_blank">Allen Institute for AI (AI2)</a> in sunny Seattle.
            <br>I am also an Affiliate Associate Professor at the Computer Science & Engineering department at the <a href="https://www.cs.washington.edu/" target="_blank">University of Washington</a>.
          </p>

          <p>
            I got my Ph.D. at the <a href="http://www.ece.umd.edu/" target="_blank">University of Maryand, College Park</a>
            under the supervision of <a href="http://www.umiacs.umd.edu/~lsd/" target="_blank">Prof. Larry S. Davis</a>.
          <br>
            My research interests lie at the intersection of vision, language and embodiment.
          </p>

          <p>
            I also enjoy building and deploying computer vision and machine learning applications for users to interact with. Prior to AI2, I spent five years at Microsoft Bing,
            building very large scale and efficient machine learning systems in the Image &amp; Video Search Relevance team.
          </p>

          <p>
            I grew up in the wonderful city of Pune in the Western part of India -- watching cricket, rowing at my college boat club, feasting on local delicacies and tinkering with robots.
          </p>

        </h6>
        <br>
        <a class="waves-effect waves-light btn indigo lighten-1" href="mailto:anik@allenai.org">Email</a>
        <a class="waves-effect waves-light btn indigo lighten-1" href="https://scholar.google.com/citations?user=JnUevM0AAAAJ">Google Scholar</a>
        <a class="waves-effect waves-light btn indigo lighten-1" href="https://twitter.com/anikembhavi">Twitter</a>
        <!-- <a class="waves-effect waves-light btn blue lighten-1">CV (Short)</a> -->
        <!-- <a class="waves-effect waves-light btn blue lighten-1">CV (Long)</a> -->
    </div>

    <div class="col s12 m3 center-on-small-only">
      <div class="image-container">
        <img class="circle responsive-img" src="images/profile_aniK.jpg">
      </div>
    </div>

      </div>
    </div>
  <div class="divider"></div>
</div>

<!--
  Research
-->

<div class="container" id="research">
  <div class="section">
    <div class="row">
      <p></p>
    </div>
    <div class="row">
      <h5>Research</h5>
    </div>
    <div class="row">
      <h6 class="light">
        My current research interests can be broadly categorized into three areas.
      </h6>
    </div>

    <div class="row">
      <div class="col s12 m4">
        <div class="icon-block">
          <h2 class="center light-blue-text"><i class="material-icons">image</i><i class="material-icons">article</i></h2>
          <h5 class="center">Vision-and-Language</h5>
          <p class="light">
            How do we create multimodal AI systems ? How can we train models that can both parse and produce, visual and language data ?
          </p>
          <p class="light">
            My recent explorations in this direction include our works on training <a href="https://arxiv.org/pdf/2104.00743">General Purpose Vision</a> systems
            and scaling up their concept vocabularies using <a href="https://arxiv.org/pdf/2202.02317">webly supervised data</a>.
          </p>
        </div>
      </div>

      <div class="col s12 m4">
        <div class="icon-block">
          <h2 class="center light-blue-text"><i class="material-icons">adb</i></h2>
          <h5 class="center">Embodied AI</h5>
          <p class="light">
            How do we train embodied agents that can interact with the real world ? I'm interested in teaching these agents to interact, but also interested in seeing what they learn via these interactions.
          </p>
          <p class="light">
            My recent works in this direction include learning to <a href="https://arxiv.org/pdf/2104.11213.pdf">manipulate</a>,
            <a href="https://arxiv.org/pdf/2103.16544.pdf">rearrange</a> and
            <a href="https://arxiv.org/pdf/2007.04979">collaborate</a> as well as learning generalizable representations
            via <a href="https://openreview.net/pdf?id=UuchYL8wSZo">game play</a>.
          </p>
        </div>
      </div>

      <div class="col s12 m4">
        <div class="icon-block">
          <h2 class="center light-blue-text"><i class="material-icons">mood</i></h2>
          <h5 class="center">AI for the common good</h5>
          <p class="light">
            I'm passionate about using computer vision and machine learning algorithms within applications that can benefit humanity and our planet.
          </p>
          <p class="light">
            My recent work in this direction includes using computer vision to detect illegal fishing vessels within the <a href="https://www.skylight.global/">Skylight</a> product.
            This work won the 4th prize (out of several hundred entires) at the <a href="https://www.diu.mil/latest/xview3-winners-announced">xView3</a> competition.
          </p>
        </div>
      </div>
    </div>

    <br>
    <div class="row">
      <h6 class="light">
        I am also passionate about <span class="purple-text"><b>open source software</b></span>.
        <p>In the PRIOR team, we spend a considerable amount of time and effort to collect and release
        <span class="purple-text"><b>new datasets</b></span> that can help us and others build powerful systems, release <span class="purple-text"><b>code</b></span> that can be used to replicate our experiments and build
        <span class="purple-text"><b>live demos</b></span> for our research projects that can enable everyone to interact with our models.
      <p>

      We build and maintain two popular open source packages for research in Embodied AI.

      <blockquote>
        <b><a href="https://ai2thor.allenai.org/">AI2-THOR</a> : </b>Near Photo-Realistic Interactable Environments for Embodied AI Agents
      </blockquote>
      <p>
      <blockquote>
        <b><a href="https://allenact.org/">AllenAct</a> : </b> A modular and flexible reinforcement learning framework for Embodied AI
      </blockquote>

      We also build and host many demos for state of the art vision models built by us and the broader community.
      <blockquote>
        <b><a href="https://vision-explorer.allenai.org/">Vision Explorer</a> : </b> Demos ranging from Recognition and Human Pose Estimation to Depth Estimation
      </blockquote>

      </h6>


    </div>

    </div>
  <div class="divider"></div>
</div>


<!--
  Recent Highlights
-->

<div class="container" id="recent">
  <div class="section">
    <div class="row">
      <p></p>
    </div>
    <div class="row">
      <h5>Recent Highlights</h5>
    </div>

    <table class="striped">
      <tbody>
        <tr>
          <td>Apr 2022</td>
          <td>New large benchmark for Computer Vision: GRIT</td>
        </tr>
        <tr>
          <td>Mar 2022</td>
          <td>3 papers accepted to CVPR 2022: General Purpose Vision <span class='special'>(Oral)</span>, Embodied-CLIP and Interpretability for Embodied AI.</td>
        </tr>
        <tr>
          <td>Oct 2021</td>
          <td>2 papers accepted to Neurips 2021: Container and Advisor.</td>
        </tr>
        <tr>
          <td>Sep 2021</td>
          <td>Invited talk at <a href="https://event.technologyreview.com/emtech-mit-2021/home">EmTech 2021</a> - MIT Tech Review's flagship event on emerging technology and global trends.</td>
        </tr>
        <tr>
          <td>Sep 2021</td>
          <td>1 paper accepted to EMNLP 2021: Iconary <span class='special'>(Oral)</span></td>
        </tr>
        <tr>
          <td>Aug 2021</td>
          <td>2 papers accepted to ICCV 2021: RobustNav <span class='special'>(Oral)</span> and GridToPix</td>
        </tr>
        <tr>
          <td>Jul 2021</td>
          <td>1 paper accepted to ACL 2021: Piglet <span class='special'>(Oral)</span></td>
        </tr>
        <tr>
          <td>Jun 2021</td>
          <td>Serving as an Area Chair for ICLR 2022</td>
        </tr>
        <tr>
          <td>Mar 2021</td>
          <td>Serving as an Area Chair for ACL 2021</td>
        </tr>
        <tr>
          <td>Feb 2021</td>
          <td>3 papers accepted to CVPR 2021: ManipulaTHOR <span class='special'>(Oral)</span>, Rearrangement <span class='special'>(Oral)</span> and VidSitu</td>
        </tr>
        <tr>
          <td>Jan 2021</td>
          <td>Serving as an Area Chair for CVPR 2021</td>
        </tr>
        <tr>
          <td>Jan 2021</td>
          <td>Hide and Seek paper has been accepted as an <span class='special'>(Oral)</span> presentation to ICLR 2021.</td>
        </tr>
      </tbody>
    </table>


    </div>
  <br>
  <div class="divider"></div>

</div>


<!--
  Publications & Preprints
-->

<div class="container" id="publications">
  <div class="section">
    <div class="row">
      <p></p>
    </div>
    <div class="row">
      <h5>Publications & Preprints</h5>
    </div>

    <ul class="collapsible z-depth-0">
      <li class="active">
        <div class="collapsible-header blue-grey lighten-5"><i class="material-icons">arrow_drop_down_circle</i>2022</div>
        <div class="collapsible-body">

          <div class="card">
            <div class="padcard">
            <div class="row">
              <div class="col s12 m2 center-on-small-only">
                <div class="image-container">
                  <img class="responsive-img" src="images/grit.jpg">
                  </div>
              </div>
              <div class="col s12 m10">
                <span class="card-title blue-text darken-4">GRIT: General Robust Image Task Benchmark</span>
                <br>Tanmay Gupta, Ryan Marten, Aniruddha Kembhavi, Derek Hoiem
                <h6 class="light"><i>ArXiv 2022</i></h6>
              </div>
            </div>

            <div class="card-action">
              <a href="https://arxiv.org/pdf/2204.13653">PDF</a>
              <a href="https://grit-benchmark.org/">Project Page</a>
              <a href="https://github.com/allenai/grit_official">Code</a>
            </div>
          </div>
        </div>

          <div class="card">
            <div class="padcard">
            <div class="row">
              <div class="col s12 m2 center-on-small-only">
                <div class="image-container">
                  <img class="responsive-img" src="images/gpv1.jpg">
                  </div>
              </div>
              <div class="col s12 m10">
                <span class="card-title blue-text darken-4">Towards General Purpose Vision Systems</span>
                <br>Tanmay Gupta, Amita Kamath, Aniruddha Kembhavi, Derek Hoiem
                <h6 class="light"><i>CVPR 2022  <span class='special'>[Oral Presentation]</span></i></h6>
              </div>
            </div>
            <div class="card-action">
              <a href="https://arxiv.org/pdf/2104.00743">PDF</a>
              <a href="https://prior.allenai.org/projects/gpv">Project Page</a>
              <a href="https://github.com/allenai/gpv-1/">Code</a>
            </div>
          </div>
        </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/embclip.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">Simple but Effective: CLIP Embeddings for Embodied AI</span>
            <br>Apoorv Khandelwal, Luca Weihs, Roozbeh Mottaghi, Aniruddha Kembhavi
            <h6 class="light"><i>CVPR 2022</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/pdf/2111.09888.pdf">PDF</a>
          <a href="https://github.com/allenai/embodied-clip">Code</a>
        </div>
      </div>
    </div>

    <div class="card">
      <div class="padcard">
      <div class="row">
        <div class="col s12 m2 center-on-small-only">
          <div class="image-container">
            <img class="responsive-img" src="images/interpret.jpg">
            </div>
        </div>
        <div class="col s12 m10">
          <span class="card-title blue-text darken-4">What do navigation agents learn about their environment?</span>
          <br>Kshitij Dwivedi, Gemma Roig, Aniruddha Kembhavi, Roozbeh Mottaghi
          <h6 class="light"><i>CVPR 2022</i></h6>
        </div>
      </div>
    </div>
  </div>

  </div>
  </li>

  <li>
    <div class="collapsible-header blue-grey lighten-5"><i class="material-icons">arrow_drop_down_circle</i>2021</div>
    <div class="collapsible-body">

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/container.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">Container: Context Aggregation Networks</span>
            <br>Gao Peng, Jiasen Lu, Hongsheng Li, Roozbeh Mottaghi, Aniruddha Kembhavi
            <h6 class="light"><i>Neurips 2021</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/pdf/2106.01401.pdf">PDF</a>
          <a href="https://github.com/allenai/container">Code</a>
        </div>
      </div>
    </div>

    <div class="card">
      <div class="padcard">
      <div class="row">
        <div class="col s12 m2 center-on-small-only">
          <div class="image-container">
            <img class="responsive-img" src="images/advisor.jpg">
            </div>
        </div>
        <div class="col s12 m10">
          <span class="card-title blue-text darken-4">Bridging the Imitation Gap by Adaptive Insubordination</span>
          <br>Luca Weihs, Unnat Jain, Iou-Jen Liu, Jordi Salvador, Svetlana Lazebnik, Aniruddha Kembhavi, Alexander Schwing
          <h6 class="light"><i>Neurips 2021</i></h6>
        </div>
      </div>

      <div class="card-action">
        <a href="https://arxiv.org/pdf/2007.12173">PDF</a>
        <a href="https://unnat.github.io/advisor/">Project Page</a>
      </div>
    </div>
  </div>

  <div class="card">
    <div class="padcard">
    <div class="row">
      <div class="col s12 m2 center-on-small-only">
        <div class="image-container">
          <img class="responsive-img" src="images/robustnav.jpg">
          </div>
      </div>
      <div class="col s12 m10">
        <span class="card-title blue-text darken-4">RobustNav : Towards Benchmarking Robustness in Embodied Navigation</span>
        <br>Prithvijit Chattopadhyay, Judy Hoffman, Roozbeh Mottaghi, Aniruddha Kembhavi
        <h6 class="light"><i>ICCV 2021 <span class='special'>[Oral Presentation]</span></i></h6>
      </div>
    </div>

    <div class="card-action">
      <a href="https://arxiv.org/pdf/2106.04531">PDF</a>
      <a href="https://prior.allenai.org/projects/robustnav">Project Page</a>
      <a href="https://github.com/allenai/robustnav">Code</a>
    </div>
  </div>
</div>

<div class="card">
  <div class="padcard">
  <div class="row">
    <div class="col s12 m2 center-on-small-only">
      <div class="image-container">
        <img class="responsive-img" src="images/gridtopix.jpg">
        </div>
    </div>
    <div class="col s12 m10">
      <span class="card-title blue-text darken-4">GridToPix: Training Embodied Agents with Minimal Supervision</span>
      <br>Unnat Jain, Iou-Jen Liu, Svetlana Lazebnik, Aniruddha Kembhavi, Luca Weihs, Alexander Schwing
      <h6 class="light"><i>ICCV 2021</i></h6>
    </div>
  </div>

  <div class="card-action">
    <a href="https://arxiv.org/pdf/2105.00931">PDF</a>
    <a href="https://unnat.github.io/gridtopix/">Project Page</a>
  </div>
</div>
</div>

<div class="card">
  <div class="padcard">
  <div class="row">
    <div class="col s12 m2 center-on-small-only">
      <div class="image-container">
        <img class="responsive-img" src="images/piglet.jpg">
        </div>
    </div>
    <div class="col s12 m10">
      <span class="card-title blue-text darken-4">PIGLeT: Language Grounding Through Neuro-Symbolic Interaction in a 3D World</span>
      <br>Rowan Zellers, Ari Holtzman, Matthew Peters, Roozbeh Mottaghi, Aniruddha Kembhavi, Ali Farhadi, Yejin Choi
      <h6 class="light"><i>ACL 2021 <span class='special'>[Oral Presentation]</span></i></h6>
    </div>
  </div>

  <div class="card-action">
    <a href="https://arxiv.org/pdf/2106.00188">PDF</a>
    <a href="https://rowanzellers.com/piglet/">Project Page</a>
  </div>
</div>
</div>

<div class="card">
  <div class="padcard">
  <div class="row">
    <div class="col s12 m2 center-on-small-only">
      <div class="image-container">
        <img class="responsive-img" src="images/manipulathor.jpg">
        </div>
    </div>
    <div class="col s12 m10">
      <span class="card-title blue-text darken-4">ManipulaTHOR: A Framework for Visual Object Manipulation</span>
      <br>Kiana Ehsani, Winson Han, Alvaro Herrasti, Eli VanderBilt, Luca Weihs, Eric Kolve, Aniruddha Kembhavi, Roozbeh Mottaghi
      <h6 class="light"><i>CVPR 2021</i></h6>
    </div>
  </div>

  <div class="card-action">
    <a href="https://arxiv.org/pdf/2104.11213.pdf">PDF</a>
    <a href="https://ai2thor.allenai.org/manipulathor">Project Page</a>
  </div>
</div>
</div>

<div class="card">
  <div class="padcard">
  <div class="row">
    <div class="col s12 m2 center-on-small-only">
      <div class="image-container">
        <img class="responsive-img" src="images/rearrangement.jpg">
        </div>
    </div>
    <div class="col s12 m10">
      <span class="card-title blue-text darken-4">Visual Room Rearrangement</span>
      <br>Luca Weihs, Matt Deitke, Aniruddha Kembhavi, Roozbeh Mottaghi
      <h6 class="light"><i>CVPR 2021</i></h6>
    </div>
  </div>

  <div class="card-action">
    <a href="https://arxiv.org/pdf/2103.16544.pdf">PDF</a>
    <a href="https://ai2thor.allenai.org/rearrangement">Project Page</a>
  </div>
</div>
</div>

<div class="card">
  <div class="padcard">
  <div class="row">
    <div class="col s12 m2 center-on-small-only">
      <div class="image-container">
        <img class="responsive-img" src="images/vidsitu.jpg">
        </div>
    </div>
    <div class="col s12 m10">
      <span class="card-title blue-text darken-4">Visual Semantic Role Labeling for Video Understanding</span>
      <br>Arka Sadhu, Tanmay Gupta, Mark Yatskar, Ram Nevatia, Aniruddha Kembhavi
      <h6 class="light"><i>CVPR 2021</i></h6>
    </div>
  </div>

  <div class="card-action">
    <a href="https://arxiv.org/pdf/2104.00990">PDF</a>
    <a href="https://vidsitu.org">Project Page</a>
    <a href="https://github.com/TheShadow29/VidSitu">Code</a>
  </div>
</div>
</div>

<div class="card">
  <div class="padcard">
  <div class="row">
    <div class="col s12 m2 center-on-small-only">
      <div class="image-container">
        <img class="responsive-img" src="images/hideseek.jpg">
        </div>
    </div>
    <div class="col s12 m10">
      <span class="card-title blue-text darken-4">Learning Generalizable Visual Representations via Interactive Gameplay</span>
      <br>Luca Weihs, Aniruddha Kembhavi, Winson Han, Alvaro Herrasti, Eric Kolve, Dustin Schwenk, Roozbeh Mottaghi, Ali Farhadi
      <h6 class="light"><i>ICLR 2021</i></h6>
    </div>
  </div>

  <div class="card-action">
    <a href="https://openreview.net/pdf?id=UuchYL8wSZo">PDF</a>
  </div>
</div>
</div>


    </div>
  </li>

  <li>
    <div class="collapsible-header blue-grey lighten-5"><i class="material-icons">arrow_drop_down_circle</i>2020</div>
    <div class="collapsible-body">

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/x-lxmert.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">X-LXMERT: Paint, Caption and Answer Questionswith Multi-Modal Transformers</span>
            <br>Jaemin Cho, Jiasen Lu, Dustin Schwenk, Hannaneh Hajishirzi, Aniruddha Kembhavi
            <h6 class="light"><i>EMNLP 2020</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/pdf/2009.11278">PDF</a>
          <a href="https://prior.allenai.org/projects/x-lxmert">Project Page</a>
          <a href="https://vision-explorer.allenai.org/text_to_image_generation">Demo</a>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/learningobjects.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">Learning About Objects by Learning to Interact with Them</span>
            <br>Martin Lohmann, Jordi Salvador, Aniruddha Kembhavi, Roozbeh Mottaghi
            <h6 class="light"><i>Neurips 2020</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/pdf/2006.09306">PDF</a>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/supsup.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">Supermasks in Superposition</span>
            <br>Mitchell Wortsman, Vivek Ramanujan, Rosanne Liu, Aniruddha Kembhavi, Mohammad Rastegari, Jason Yosinski, Ali Farhadi
            <h6 class="light"><i>Neurips 2020</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/pdf/2006.14769">PDF</a>
          <a href="https://mitchellnw.github.io/blog/2020/supsup/">Blog post</a>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/allenact.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">AllenAct: A Framework for Embodied AI Research</span>
            <br>Luca Weihs, Jordi Salvador, Klemen Kotar, Unnat Jain, Kuo-Hao Zeng, Roozbeh Mottaghi, Aniruddha Kembhavi
            <h6 class="light"><i>ArXiv 2020</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/pdf/2008.12760">PDF</a>
          			<a href="http://allenact.org/">Project Page</a>
                <a href="https://github.com/allenai/allenact">Code</a>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/cordialsync.gif">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">A Cordial Sync: Going Beyond Marginal Policies for Multi-Agent Embodied Tasks</span>
            <br>Unnat Jain, Luca Weihs, Eric Kolve, Ali Farhadi, Svetlana Lazebnik, Aniruddha Kembhavi, Alexander Schwing
            <h6 class="light"><i>ECCV 2020</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/pdf/2007.04979">PDF</a>
    			<a href="https://unnat.github.io/cordial-sync">Project Page</a>
          <a href="https://github.com/allenai/cordial-sync">Code</a>
          <a href="https://youtu.be/EnYwCX5E9gk">Teaser Video</a>
          <a href="https://youtu.be/xM3auncA06A">Detailed Video</a>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/gsr.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">Grounded Situation Recognition</span>
            <br>Sarah Pratt, Mark Yatskar, Luca Weihs, Ali Farhadi, Aniruddha Kembhavi
            <h6 class="light"><i>ECCV 2020</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/pdf/2003.12058">PDF</a>
    			<a href="https://prior.allenai.org/projects/gsr">Project Page</a>
          <a href="https://github.com/allenai/swig">Code</a>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/ned.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">In the Wild: From ML Models to Pragmatic ML Systems</span>
            <br>Matthew Wallingford, Aditya Kusupati, Keivan Alizadeh-Vahid, Aaron Walsman, Aniruddha Kembhavi, Ali Farhadi
            <h6 class="light"><i>ArXiv 2020</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/pdf/2007.02519">PDF</a>
          <a href="https://raivn.cs.washington.edu/projects/InTheWild/">Project Page</a>
          <a href="https://github.com/RAIVNLab/InTheWild">Code</a>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/objectnav.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">ObjectNav Revisited: On Evaluation of Embodied Agents Navigating to Objects</span>
            <br>Dhruv Batra, Aaron Gokaslan, Ani Kembhavi, Oleksandr Maksymets, Roozbeh Mottaghi, Manolis Savva, Alexander Toshev, Erik Wijmans
            <h6 class="light"><i>ArXiv 2020</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/pdf/2006.13171">PDF</a>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/robothor.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">RoboTHOR: An Open Simulation-to-Real Embodied AI Platform</span>
            <br>Matt Deitke*, Winson Han*, Alvaro Herrasti*, Aniruddha Kembhavi*, Eric Kolve*, Roozbeh Mottaghi*, Jordi Salvador*, Dustin Schwenk*, Eli VanderBilt*, Matthew Wallingford*, Luca Weihs*, Mark Yatskar*, Ali Farhadi
            <h6 class="light"><i>CVPR 2020</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/pdf/2004.06799.pdf">PDF</a>
          <a href="https://ai2thor.allenai.org/robothor/">Project Page</a>>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/hidden.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">What’s Hidden in a Randomly Weighted Neural Network?</span>
            <br>Vivek Ramanujan, Mitchell Wortsman, Aniruddha Kembhavi, Ali Farhadi, Mohammad Rastegari
            <h6 class="light"><i>CVPR 2020</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/pdf/1911.13299.pdf">PDF</a>
        </div>
      </div>
      </div>


    </div>
  </li>

  <li>
    <div class="collapsible-header blue-grey lighten-5"><i class="material-icons">arrow_drop_down_circle</i>2019</div>
    <div class="collapsible-body">

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/twobody.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">Two Body Problem: Collaborative Visual Task Completion</span>
            <br>Unnat Jain, Luca Weihs, Eric Kolve, Mohammad Rastegari, Svetlana Lazebnik, Ali Farhadi, Alexander Schwing, Aniruddha Kembhavi
            <h6 class="light"><i>CVPR 2019 <span class='special'>[Oral Presentation]</span></i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/pdf/1904.05879.pdf">PDF</a>
    			<a href="https://prior.allenai.org/projects/two-body-problem">Project Page</a>
    			<a href="https://www.youtube.com/watch?v=VWqawSuH-eU">Video</a>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/elastic.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">ELASTIC: Improving CNNs with Instance Specific Scaling Policies</span>
            <br>Huiyu Wang, Aniruddha Kembhavi, Ali Farhadi, Alan Yuille, Mohammad Rastegari
            <h6 class="light"><i>CVPR 2019 <span class='special'>[Oral Presentation]</span></i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/pdf/1812.05262.pdf">PDF</a>
          <a href="https://prior.allenai.org/projects/elastic">Project Page</a>
        </div>
      </div>
      </div>
    </div>
  </li>

  <li>
    <div class="collapsible-header blue-grey lighten-5"><i class="material-icons">arrow_drop_down_circle</i>2018</div>
    <div class="collapsible-body">

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/flintstones.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">Imagine This! Scripts to Compositions to Videos</span>
            <br>Tanmay Gupta, Dustin Schwenk, Ali Farhadi, Derek Hoiem, Aniruddha Kembhavi
            <h6 class="light"><i>ECCV 2018</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/abs/1804.03608">PDF</a>
    			<a href="https://prior.allenai.org/projects/craft">Project Page</a>
    			<a href="https://www.youtube.com/watch?v=688Vv86n0z8">Video</a>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/iqa.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">IQA: Visual Question Answering in Interactive Environments</span>
            <br>Daniel Gordon, Aniruddha Kembhavi, Mohammad Rastegari, Joseph Redmon, Dieter Fox, Ali Farhadi
            <h6 class="light"><i>CVPR 2018</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/abs/1712.03316">PDF</a>
          <a href="https://prior.allenai.org/projects/iqa">Project Page</a>
          <a href="https://www.youtube.com/watch?v=pXd3C-1jr98">Video</a>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/matching.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">Structured Set Matching Networks for One-Shot Part Labeling</span>
            <br>Jonghyun Choi, Jayant Krishnamurthy, Aniruddha Kembhavi, Ali Farhadi
            <h6 class="light"><i>CVPR 2018 <span class='special'>[Spotlight Presentation]</span></i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/abs/1712.01867">PDF</a>
          <a href="https://prior.allenai.org/projects/matching-part-label">Project Page</a>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/gvqa.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering</span>
            <br>Aishwarya Agrawal, Dhruv Batra, Devi Parikh, Aniruddha Kembhavi
            <h6 class="light"><i>CVPR 2018</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/abs/1712.00377">PDF</a>
        </div>
      </div>
      </div>
    </div>
  </li>

  <li>
    <div class="collapsible-header blue-grey lighten-5"><i class="material-icons">arrow_drop_down_circle</i>2017</div>
    <div class="collapsible-body">

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/tqa.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">Are You Smarter Than A Sixth Grader? Textbook Question Answering for Multimodal Machine Comprehension</span>
            <br>Aniruddha Kembhavi, Minjoon Seo, Dustin Schwenk, Jonghyun Choi, Ali Farhadi, Hannaneh Hajishirzi
            <h6 class="light"><i>CVPR 2017</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="http://ai2-website.s3.amazonaws.com/publications/CVPR17_TQA.pdf">PDF</a>
    			<a href="http://prior.allenai.org/projects/tqa/">Project Page</a>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/bidaf.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">Bidirectional Attention Flow for Machine Comprehension</span>
            <br>Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hannaneh Hajishirzi
            <h6 class="light"><i>ICLR 2017</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/abs/1611.01603">PDF</a>
    			<a href="https://prior.allenai.org/projects/bidaf/">Project Page</a>
    			<a href="https://github.com/allenai/bi-att-flow">Code</a>
        </div>
      </div>
      </div>
    </div>
  </li>

  <li>
    <div class="collapsible-header blue-grey lighten-5"><i class="material-icons">arrow_drop_down_circle</i>2016</div>
    <div class="collapsible-body">

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/diagrams.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">A diagram is worth a dozen images</span>
            <br>Aniruddha Kembhavi, Mike Salvato, Eric Kolve, Minjoon Seo, Hannaneh Hajishirzi, Ali Farhadi
            <h6 class="light"><i>ECCV 2016</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/abs/1603.07396">PDF</a>
          <a href="http://prior.allenai.org/projects/diagram-understanding">Project Page</a>
        </div>
      </div>
      </div>

      <div class="card">
        <div class="padcard">
        <div class="row">
          <div class="col s12 m2 center-on-small-only">
            <div class="image-container">
              <img class="responsive-img" src="images/pparsing.jpg">
              </div>
          </div>
          <div class="col s12 m10">
            <span class="card-title blue-text darken-4">Semantic Parsing to Probabilistic Programs for Situated Question Answering</span>
            <br>Jayant Krishnamurthy, Oyvind Tafjord, Aniruddha Kembhavi
            <h6 class="light"><i>EMNLP 2016</i></h6>
          </div>
        </div>

        <div class="card-action">
          <a href="https://arxiv.org/abs/1606.07046">PDF</a>
          <a href="https://github.com/jayantk/jklol/tree/master/src/com/jayantkrish/jklol/experiments/p3">Code</a>
        </div>
      </div>
      </div>
    </div>
  </li>

  <li>
    <div class="collapsible-header blue-grey lighten-5"><i class="material-icons">arrow_drop_down_circle</i>Earlier than 2016</div>
    <div class="collapsible-body">
      <span>For older publications, please refer to:</span>
      <p>
      <a class="waves-effect waves-light btn indigo lighten-1" href="https://scholar.google.com/citations?user=JnUevM0AAAAJ">Google Scholar</a>
      <a class="waves-effect waves-light btn blue lighten-1" href="https://www.semanticscholar.org/author/Aniruddha-Kembhavi/2684226">Semantic Scholar</a>
    </div>
  </li>

  </ul>
  </div>

  <br>
  <div class="divider"></div>
</div>


<!--
  Collaborators
-->

<div class="container" id="collaborators">
  <div class="section">
    <div class="row">
      <p></p>
    </div>
    <div class="row">
      <h5>Collaborators</h5>
    </div>
    <div class="row">
      <h6 class="light">
        I enjoy working in collaborative teams. Over the past few years, I've had the pleasure of working with
        many colleagues at AI2, but also with several researchers at other institutions.
      </h6>

      <br>
      <h6 class="light">
        Professors I have had close collaborations with include (recent interactions on top):
      </h6>

      <div class="row">
        <div class="col s12 m8">
      <table class="stripedx">
        <tbody>
          <tr>
            <td>Prof. Ali Farhadi</td>
            <td>University of Washington + Apple</td>
          </tr>

          <tr>
            <td>Prof. Derek Hoiem</td>
            <td>University of Illinois at Urbana-Champaign</td>
          </tr>

          <tr>
            <td>Prof. Renée Baillargeon</td>
            <td>University of Illinois at Urbana-Champaign</td>
          </tr>

          <tr>
            <td>Prof. Cynthia Fisher</td>
            <td>University of Illinois at Urbana-Champaign</td>
          </tr>

          <tr>
            <td>Prof. Judy Hoffman</td>
            <td>Georgia Institute of Technology</td>
          </tr>

          <tr>
            <td>Prof. Alex Schwing</td>
            <td>University of Illinois at Urbana-Champaign</td>
          </tr>

          <tr>
            <td>Prof. Devi Parikh</td>
            <td>Georgia Institute of Technology + Meta</td>
          </tr>

          <tr>
            <td>Prof. Dhruv Batra</td>
            <td>Georgia Institute of Technology + Meta</td>
          </tr>

          <tr>
            <td>Prof. Mark Yatskar</td>
            <td>University of Pennsylvania</td>
          </tr>
        </tbody>
      </table>
    </div>
  </div>

  <br>
  <h6 class="light">
    Students I have collaborated with, primarily via internships at AI2, include (recent interactions on top):
  </h6>

  <div class="row">
    <div class="col s12 m8">
  <table class="stripedy">
    <tbody>
      <tr>
        <td>Kshitij Dwivedi</td>
        <td>Goethe University Frankfurt</td>
      </tr>

      <tr>
        <td>Arka Sadhu</td>
        <td>University of Southern California</td>
      </tr>

      <tr>
        <td>Amanda Rose Yuile</td>
        <td>University of Illinois at Urbana-Champaign</td>
      </tr>

      <tr>
        <td>Peng Gao</td>
        <td>Chinese University of Hong Kong</td>
      </tr>

      <tr>
        <td>Unnat Jain</td>
        <td>University of Illinois at Urbana-Champaign</td>
      </tr>

      <tr>
        <td>Vishvak Murahari</td>
        <td>Georgia Institute of Technology</td>
      </tr>

      <tr>
        <td>Prithvijit Chattopadhyay</td>
        <td>Georgia Institute of Technology</td>
      </tr>

      <tr>
        <td>Sachin Mehta</td>
        <td>University of Washington</td>
      </tr>

      <tr>
        <td>Andrew Hoang</td>
        <td>University of Washington</td>
      </tr>

      <tr>
        <td>Huiyu Wang</td>
        <td>Johns Hopkins University</td>
      </tr>

      <tr>
        <td>Roy Or-EL</td>
        <td>University of Washington</td>
      </tr>

      <tr>
        <td>Tanmay Gupta</td>
        <td>University of Illinois at Urbana-Champaign</td>
      </tr>

      <tr>
        <td>Xun Huang</td>
        <td>Cornell University</td>
      </tr>

      <tr>
        <td>Aishwarya Agrawal</td>
        <td>Georgia Institute of Technology</td>
      </tr>

      <tr>
        <td>Daniel Gordon</td>
        <td>University of Washington</td>
      </tr>

      <tr>
        <td>Minjoon Seo</td>
        <td>University of Washington</td>
      </tr>
    </tbody>
  </table>
</div>
</div>

<br>
<h6 class="light">
  Pre-doctoral residents I have helped supervise at AI2 (recent interactions on top):
</h6>

<div class="row">
  <div class="col s12 m8">
<table class="stripedx">
  <tbody>
    <tr>
      <td>Amita Kamath</td>
      <td>Starting school at University of California, Los Angeles</td>
    </tr>

    <tr>
      <td>Apoorv Khandelwal</td>
      <td>Starting school at Brown University</td>
    </tr>

    <tr>
      <td>Kunal Pratap Singh</td>
      <td>Currently at AI2</td>
    </tr>

    <tr>
      <td>Sarah Pratt</td>
      <td>Now at University of Washington</td>
    </tr>

    <tr>
      <td>Vivek Ramanujan</td>
      <td>Now at University of Washington</td>
    </tr>

    <tr>
      <td>Mike Salvato</td>
      <td>Now at Northwestern University</td>
    </tr>

  </tbody>
</table>
</div>
</div>

    </div>

    </div>
  <br>
  <div class="divider"></div>

</div>


<!--
  Press
-->

<div class="container" id="press">
  <div class="section">
    <div class="row">
      <p></p>
    </div>
    <div class="row">
      <h5>Press</h5>
    </div>
    <div class="row">
      <table class="media" width="100%" border="0" cellspacing="0" cellpadding="10"><tbody>

        <tr>
          <td width="200" bgcolor="#c6edff">
            <i>Learning Generalizable Visual Representations via Interactive Gameplay</i>
          </td>
          <td>
            <p>
              <a class="media" href="https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/ai-agent-learns-about-the-world-by-gameplay"><img class="media" src="logos/ieeespectrum.png" border=2></a>
          </td>
        </tr>

        <tr>
          <td width="200" bgcolor="#eeeeee">
            <i>X-LXMERT: Teaching vision-and-language transformer models to paint</i>
          </td>
          <td>
            <p>
              <a class="media" href="https://www.technologyreview.com/2020/09/25/1008921/ai-allen-institute-generates-images-from-captions/"><img class="media" src="logos/mittechreview.png" border=2></a>
          </td>
        </tr>

        <tr>
          <td width="200" bgcolor="#c6edff">
            <i>AllenAct: An open source framework for research in Embodied AI</i>
          </td>
          <td>
            <p>
              <a class="media" href="https://venturebeat.com/2020/08/31/allen-institute-open-sources-allenact-a-framework-for-research-in-embodied-ai/"><img class="media" src="logos/venturebeat.png" border=2></a>
              <a class="media" href="https://www.hackster.io/news/bet-you-can-t-do-that-again-6fc341d01fbd/"><img class="media" src="logos/hackster.png" border=2></a>
          </td>
        </tr>

        <tr>
          <td width="200" bgcolor="#eeeeee">
            <i>AI & Creativity</i>
          </td>
          <td>
            <p>
              <a class="media" href="https://www.engadget.com/facebook-ai-choreography-170023727.html"><img class="media" src="logos/engadget.png" border=2></a>
          </td>
        </tr>

        <tr>
          <td width="250" bgcolor="#c6edff">
            <i>RoboTHOR: An Open Simulation-to-Real Embodied AI Platform</i>
          </td>
          <td>
            <p>
              <a class="media" href="https://www.technologyreview.com/s/615186/ai-ai2-robots-navigate-world-train-algorithms-challenge/"><img class="media" src="logos/mittechreview.png" border=2></a>
              <a class="media" href="https://www.geekwire.com/tag/robothor-challenge/"><img class="media" src="logos/geekwire.png" border=2></a>
          </td>
        </tr>

        <tr>
          <td width="200" bgcolor="#eeeeee">
            <i>Iconary: An AI powered drawing and guessing game</i>
          </td>
          <td>
            <p>
              <a class="media" href="https://www.sciencemag.org/news/2019/02/pictionary-playing-computer-connects-humans-deep-thoughts"><img class="media" src="logos/science.png" border=2></a>
              <a class="media" href="https://www.technologyreview.com/s/612882/an-ai-is-playing-pictionary-to-figure-out-how-the-world-works/"><img class="media" src="logos/mittechreview.png" border=2></a>
              <a class="media" href="https://venturebeat.com/2019/02/05/allen-institute-debuts-ai-that-plays-pictionary-style-games-to-learn-common-sense/"><img class="media" src="logos/venturebeat.png" border=2></a>
              <a class="media" href="https://www.wired.com/story/your-next-game-night-partner-computer-iconary/"><img class="media" src="logos/wired.png" border=2></a>
              <a class="media" href="https://spectrum.ieee.org/tech-talk/robotics/artificial-intelligence/pictionary-playing-ai-sketches-the-future-of-human-machine-collaborations"><img class="media" src="logos/ieeespectrum.png" border=2></a>
              <a class="media" href="https://techcrunch.com/2019/02/05/play-iconary-a-simple-drawing-game-that-hides-a-deceptively-deep-ai/"><img class="media" src="logos/techcrunch.png" border=2></a>
              <a class="media" href="https://www.theverge.com/2019/2/5/18211799/pictionary-computers-ai-allen-institute-for-artificial-intelligence-iconary-common-sense"><img class="media" src="logos/theverge.png" border=2></a>
              <a class="media" href="https://www.kuow.org/stories/forget-chess-this-bot-plays-pictionary"><img class="media" src="logos/kuow.png" border=2></a>
              <a class="media" href="https://www.ft.com/content/2038d96e-28e7-11e9-a5ab-ff8ef2b976c7"><img class="media" src="logos/financialtimes.png" border=2></a>
              <a class="media" href="https://techxplore.com/news/2019-02-picture-guessing-game-ai-effort-common.html"><img class="media" src="logos/techxplore.png" border=2></a>
              <a class="media" href="https://www.seattletimes.com/business/technology/what-does-the-seattle-man-who-invented-pictionary-think-about-its-artificial-intelligence-use/"><img class="media" src="logos/seattletimes.png" border=2></a>
              <a class="media" href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/artificial-intelligence-deep-thoughts-ai-pictionary-deepmind-a8764581.html"><img class="media" src="logos/independent.png" border=2></a>
          </td>
        </tr>

        <tr>
          <td width="200" bgcolor="#c6edff">
            <i>Craft: Scripts to Compositions to Videos</i>
          </td>
          <td>
            <p>
              <a class="media" href="https://www.engadget.com/2018/04/15/ai-creates-flintstones-cartoons/"><img class="media" src="logos/engadget.png" border=2></a>
              <a class="media" href="https://gizmodo.com/this-ai-can-automatically-animate-new-flintstones-carto-1825236308"><img class="media" src="logos/gizmodo.png" border=2></a>
              <a class="media" href="https://thenextweb.com/artificial-intelligence/2018/04/11/researchers-trained-an-ai-to-create-flintstones-cartoons/"><img class="media" src="logos/thenextweb.png" border=2></a>
              <a class="media" href="https://www.techtimes.com/articles/225316/20180417/this-ai-makes-flintstones-animation-based-on-text-descriptions-alone.htm"><img class="media" src="logos/techtimes.png" border=2></a>
          </td>
        </tr>



      </tbody></table>

    </div>

    </div>
  <br>
  <div class="divider"></div>

</div>


<!--
  Footer
-->

  <footer class="page-footer black">
    <div class="footer-copyright">
      <div class="container">
      This website was made using <a class="orange-text text-lighten-3" href="http://materializecss.com">Materialize</a>
      </div>
    </div>
  </footer>


  <!--  Scripts-->
  <script src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="js/materialize.js"></script>
  <script src="js/init.js"></script>

  </body>
</html>
